# -*- coding: utf-8 -*-
import scrapy
import sys
from exploit_db.items import ExploitDbItem
from scrapy.selector import HtmlXPathSelector
from scrapy import Request


class ExploitdbSpider(scrapy.Spider):
    name = "exploitdb"
    allowed_domains = ["exploit-db.com"]
    start_urls = ['https://www.exploit-db.com/rss.xml']

    def start_requests(self):
        headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:48.0) Gecko/20100101 Firefox/48.0'}
        for url in self.start_urls:
            yield Request(url, headers=headers)

    def parse(self, response):
        item = ExploitDbItem()
        for sel in response.xpath('//item'):
            item['desc'] = sel.select('description/text()').extract()
            item['link'] = sel.select('link/text()').extract()
            item['type_'] = sel.select('type/text()').extract()
            item['pubDate'] = sel.select('pubDate/text()').extract()
            yield item